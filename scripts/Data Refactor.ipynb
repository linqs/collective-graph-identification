{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f5c40c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# This notebook stores each step of refactoring the graph data into PSL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6411d281-8dec-4dc2-a5ac-556ff4f07f88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# No space between equals sign is necessary, so we can treat these as Bash variables as well.\n",
    "FILE_GROUND_TRUTH_EMAIL_NODES='../c3/namata-kdd11-data/enron/enron-samples-lowunk/outputgraph/enron.NODE.email.tab'\n",
    "FILE_GROUND_TRUTH_COREF_EDGES='../c3/namata-kdd11-data/enron/enron-samples-lowunk/outputgraph/enron.UNDIRECTED.coref.tab'\n",
    "FILE_GROUND_TRUTH_MANAGES_EDGES='../c3/namata-kdd11-data/enron/enron-samples-lowunk/outputgraph/enron.UNDIRECTED.email-submgr.tab'\n",
    "FILE_GROUND_TRUTH_COMMUNICATION_EDGES='../c3/namata-kdd11-data/enron/enron-samples-lowunk/outputgraph/enron.DIRECTED.sentto.tab'\n",
    "\n",
    "\n",
    "FILE_SAMPLE_EMAIL_NODES='../c3/namata-kdd11-data/enron/enron-samples-lowunk/enron-sample-lowunk-6of6/sample-enron.NODE.email.tab'\n",
    "FILE_SAMPLE_COREF_EDGES='../c3/namata-kdd11-data/enron/enron-samples-lowunk/enron-sample-lowunk-6of6/sample-enron.UNDIRECTED.coref.tab'\n",
    "FILE_SAMPLE_MANAGES_EDGES='../c3/namata-kdd11-data/enron/enron-samples-lowunk/enron-sample-lowunk-6of6/sample-enron.UNDIRECTED.email-submgr.tab'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b913c78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## These functions help parse the .tab files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d983d7bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools # for cross products when filling in a full PSL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57353b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# assigns types to each column\n",
    "def resolve_column_type(table):\n",
    "    for column in table.columns:\n",
    "        if column in {'id', 'email', 'alt_email', 'other_email' , 'numsent', 'numreceived', 'numexchanged'}:\n",
    "            table[column] = table[column].astype(str).astype(float).astype(int)\n",
    "        # convert bag-of-words columns to floats (since ints won't take NaNs)\n",
    "        elif re.match(\"w-\", column):\n",
    "            table[column] = table[column].astype(str).astype(float)\n",
    "\n",
    "# extracts feature name from an element in a raw tab row\n",
    "# returns: tuple (feature_name, feature_value, optional_value)\n",
    "def get_feature_tuple(feature):\n",
    "    feature_data = re.split(r\"[:=]\", feature)\n",
    "    return feature_data\n",
    "    \n",
    "\n",
    "# loads the *.tab files into a Pandas Dataframe.\n",
    "# returns: pd.DataFrame(columns=features)\n",
    "def load_table(filename):\n",
    "\n",
    "    # initialize the pandas dataframe\n",
    "    node_data = pd.DataFrame()\n",
    "\n",
    "\n",
    "    with open(filename) as infile:\n",
    "        i = 0\n",
    "        row_list = []\n",
    "        for row in infile:\n",
    "    \n",
    "            #print('i is: ', i)\n",
    "\n",
    "            if i == 0:\n",
    "                # Skip non-useful first line\n",
    "                print(\"Header: \", row)\n",
    "            elif i == 1:\n",
    "                # Prepare dataframe column labels\n",
    "                tokens = row.split()\n",
    "                if len(tokens) == 1:\n",
    "                    print(\"This is not a NODE file, so don't load this row\")\n",
    "                else:  \n",
    "                    features = [\"id\"] + [get_feature_tuple(feature)[1] for feature in tokens]\n",
    "                    node_data = pd.DataFrame(columns=features)\n",
    "            else:\n",
    "          \n",
    "                # this is to help the function generalize among the NODE and EDGE files.\n",
    "                # EDGE files have a \"|\" character, which needs to be removed for proper feature decoupling\n",
    "                row = re.sub(r'\\|','', row)\n",
    "            \n",
    "                tokens = row.split()\n",
    "\n",
    "                # the first token doesn't need splitting\n",
    "                row_dict = {'id':tokens[0]}\n",
    "                row_dict.update({get_feature_tuple(token)[0]:get_feature_tuple(token)[1] for token in tokens[1:]})\n",
    "                row_list.append(row_dict)\n",
    "        \n",
    "            i += 1\n",
    "        \n",
    "        # Fill in rows\n",
    "        node_data = pd.concat([node_data, pd.DataFrame(row_list)], ignore_index=True)\n",
    "\n",
    "    return node_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e08167d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Process the email nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48daee0e-d2bc-46e2-a209-403371aa8d47",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21fa39d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "email_nodes = load_table(FILE_GROUND_TRUTH_EMAIL_NODES)\n",
    "# remove the (unnecessary) second to last column (it came from an ambiguous parse splits)\n",
    "email_nodes.drop('other,manager,specialist,director,executive', axis=1, inplace=True)\n",
    "resolve_column_type(email_nodes)\n",
    "\n",
    "email_nodes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f0110",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "email_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be8f0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Takes a table and fills the missing pairs and values to specify a full, sufficient set\n",
    "# So far it only works with binary predicates\n",
    "def fill_observed_missing_possibilities(table, arguments, values):\n",
    "    total_possibilities = set(itertools.product(list(table[arguments[0]]), values))\n",
    "    already_observed_possibilities = set((table.loc[index][arguments[0]], table.loc[index][arguments[1]]) for index in table.index)\n",
    "\n",
    "    missing_possibilities = total_possibilities - already_observed_possibilities\n",
    "    row_list = []\n",
    "    for arg_0, arg_1 in missing_possibilities:\n",
    "        row_dict = {arguments[0]:arg_0, arguments[1]:arg_1, arguments[2]:0 }\n",
    "        row_list.append(row_dict)\n",
    "        \n",
    "    return pd.concat([table, pd.DataFrame(row_list)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43913d-8454-48dc-8456-94bda2a96c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab necessary columns, in preparation for dumping the whole ground truth data\n",
    "email_nodes_data = email_nodes[['id','title']].copy()\n",
    "\n",
    "# convert titles to integers, so PSL can ground faster\n",
    "title_map = {\"other\": 0, \"manager\": 1, \"specialist\": 2, \"director\": 3, \"executive\": 4}\n",
    "\n",
    "email_nodes_data = email_nodes_data.replace({'title': title_map})\n",
    "email_nodes_data['exists'] = 1.0\n",
    "\n",
    "full_set_email_has_label_data = fill_observed_missing_possibilities(email_nodes_data, ['id', 'title', 'exists'], list(title_map.values()))\n",
    "full_set_email_has_label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9801aa44-28d7-4efd-b7bc-2661d59dd7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Outputs all data (obs+truth)\n",
    "# full_set_email_has_label_data.to_csv('EmailHasLabel_data.csv', sep ='\\t', index=False, header=False, columns=['id', 'title', 'exists'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711200e4-4ae7-4b81-8cf2-4b3e09dcf4e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate splits for PSL predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20698d4-a4eb-4eed-a47c-cbed34fac003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab the sample from the original experiment, this will allow us to calculate observations and targets.\n",
    "sample_email_nodes = load_table(FILE_SAMPLE_EMAIL_NODES)\n",
    "# remove the (unnecessary) second to last column (it came from an ambiguous parse splits)\n",
    "sample_email_nodes.drop('other,manager,specialist,director,executive', axis=1, inplace=True)\n",
    "resolve_column_type(sample_email_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21aaed-5e18-4966-b998-61cb0826ff2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into observed and targets (AKA train and test)\n",
    "email_nodes_obs = email_nodes[email_nodes['id'].isin(sample_email_nodes[sample_email_nodes['title'].notna()]['id'])]\n",
    "email_nodes_truth = email_nodes[email_nodes['id'].isin(sample_email_nodes[sample_email_nodes['title'].isna()]['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b69008-a437-4649-ac72-25d54c74ca22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab the necessary columns\n",
    "email_has_label_obs = email_nodes_obs[['id','title']].copy()\n",
    "email_has_label_truth = email_nodes_truth[['id','title']].copy()\n",
    "\n",
    "# convert titles to integers, so PSL can ground faster\n",
    "email_has_label_obs = email_has_label_obs.replace({'title': title_map})\n",
    "email_has_label_truth = email_has_label_truth.replace({'title': title_map})\n",
    "\n",
    "# add in an existence column\n",
    "email_has_label_obs['exists'] = 1.0\n",
    "email_has_label_truth['exists'] = 1.0\n",
    "\n",
    "# email_has_label_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f655a04f-b6bb-488e-9003-486424a24869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add in the the non existent observations\n",
    "full_set_email_has_label_obs = fill_observed_missing_possibilities(email_has_label_obs, ['id', 'title', 'exists'], list(title_map.values()))\n",
    "full_set_email_has_label_truth = fill_observed_missing_possibilities(email_has_label_truth, ['id', 'title', 'exists'], list(title_map.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33d9ed-0700-4e2a-adbb-dab78b3a7104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Outputs splits to file\n",
    "#full_set_email_has_label_obs.to_csv('EmailHasLabel_obs.csv', sep ='\\t', index=False, header=False)\n",
    "#full_set_email_has_label_truth.to_csv('EmailHasLabel_truth.csv', sep ='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b8581e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Process the CoRef edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c8b54f-4ee2-4988-8fc0-a4ed4970bf67",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d78f98a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to rename one of the columns due to key collision\n",
    "# use copy for safety\n",
    "\n",
    "!cp $FILE_GROUND_TRUTH_COREF_EDGES .\n",
    "!sed -i 's/email/alt_email/2g' enron.UNDIRECTED.coref.tab\n",
    "\n",
    "coref_edges = load_table('enron.UNDIRECTED.coref.tab')\n",
    "resolve_column_type(coref_edges)\n",
    "\n",
    "coref_edges.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cad36a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coref_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72fc11f-0132-44ac-b59f-368e79ccae8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab necessary columns, in preparation for dumping the whole ground truth data\n",
    "coref_edges_data = coref_edges[['email','alt_email', 'exists']].copy()\n",
    "\n",
    "# convert existence column to boolean, so PSL can ground faster\n",
    "exists_map = {\"NOTEXIST\": 0.0, \"EXIST\": 1.0}\n",
    "coref_edges_data = coref_edges_data.replace({'exists': exists_map})\n",
    "\n",
    "# Since it's undirected, add in the reverse edges.\n",
    "coref_edges_data_sym = coref_edges_data[['alt_email', 'email', 'exists']].copy()\n",
    "coref_edges_data_sym.rename(columns = {'alt_email':'email', 'email':'alt_email'}, inplace = True)\n",
    "\n",
    "coref_edges_data = pd.concat([coref_edges_data, coref_edges_data_sym])\n",
    "\n",
    "# Calculated the missing edges that were blocked.\n",
    "missing_edges = {pair for pair in itertools.permutations(email_nodes['id'], 2)} - {pair for pair in zip(coref_edges_data['email'], coref_edges_data['alt_email'])}\n",
    "\n",
    "# add in the missing edges\n",
    "row_list = []\n",
    "for email, alt_email in missing_edges:\n",
    "    row_dict = {'email':email, 'alt_email':alt_email, 'exists':0 }\n",
    "    row_list.append(row_dict)\n",
    "\n",
    "full_set_coref_edges_data = pd.concat([coref_edges_data, pd.DataFrame(row_list)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b9b44c-038c-4adb-a5d9-80ee9d9b875c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Outputs to file\n",
    "# full_set_coref_edges_data.to_csv('CoRef_data.csv', sep ='\\t', index=False, header=False, columns=['email', 'alt_email', 'exists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a82ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity Check: These should print pairs of the same people\n",
    "# for index in full_set_coref_edges_data[full_set_coref_edges_data['exists'] == 1.0][['email', 'alt_email']].index:\n",
    "#     email_id  = full_set_coref_edges_data.loc[index]['email'].iloc[0]\n",
    "#     alt_email_id = full_set_coref_edges_data.loc[index]['alt_email'].iloc[0]\n",
    "    \n",
    "#     print(email_nodes[email_nodes['id'] == email_id]['emailaddress'])\n",
    "#     print(email_nodes[email_nodes['id'] == alt_email_id]['emailaddress'])\n",
    "#     print(\"------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccf9df6-8805-4575-89fc-d549bb462d12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate splits for PSL predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e13159-d275-447c-88a5-6a4631ddb688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab the sample from the original experiment, this will allow us to calculate observations and targets.\n",
    "sample_coref_edges = load_table(FILE_SAMPLE_COREF_EDGES)\n",
    "resolve_column_type(sample_coref_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f4b581-b7fc-4a86-a9ef-1a70a88e86ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into observed and targets (AKA train and test)\n",
    "coref_edges_obs = coref_edges[coref_edges['id'].isin(sample_coref_edges[sample_coref_edges['exists'].notna()]['id'])]\n",
    "coref_edges_truth = coref_edges[coref_edges['id'].isin(sample_coref_edges[sample_coref_edges['exists'].isna()]['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43183cbf-d700-4d4e-aa59-9888ff135021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab the necessary columns\n",
    "coref_obs = coref_edges_obs[['email', 'alt_email', 'exists']].copy()\n",
    "coref_truth = coref_edges_truth[['email', 'alt_email', 'exists']].copy()\n",
    "\n",
    "# convert existence column to boolean, so PSL can ground faster\n",
    "coref_obs = coref_obs.replace({'exists': exists_map})\n",
    "coref_truth = coref_truth.replace({'exists': exists_map})\n",
    "\n",
    "# Since it's undirected, add in the reverse edges.\n",
    "coref_obs_sym = coref_obs[['alt_email', 'email', 'exists']].copy()\n",
    "coref_truth_sym = coref_truth[['alt_email', 'email', 'exists']].copy()\n",
    "\n",
    "coref_obs_sym.rename(columns = {'alt_email':'email', 'email':'alt_email'}, inplace = True)\n",
    "coref_truth_sym.rename(columns = {'alt_email':'email', 'email':'alt_email'}, inplace = True)\n",
    "\n",
    "coref_obs = pd.concat([coref_obs, coref_obs_sym], ignore_index=True)\n",
    "coref_truth = pd.concat([coref_truth, coref_truth_sym], ignore_index=True)\n",
    "\n",
    "# Calculated the missing edges that were blocked. Note the last set prevents cross contamination\n",
    "missing_edges = {pair for pair in itertools.permutations(email_nodes['id'], 2)} - {pair for pair in zip(coref_obs['email'], coref_obs['alt_email'])} - {pair for pair in zip(coref_truth['email'], coref_truth['alt_email'])}\n",
    "\n",
    "# add in the missing edges\n",
    "row_list = []\n",
    "for email, alt_email in missing_edges:\n",
    "    row_dict = {'email':email, 'alt_email':alt_email, 'exists':0 }\n",
    "    row_list.append(row_dict)\n",
    "\n",
    "full_set_coref_edges_obs = pd.concat([coref_obs, pd.DataFrame(row_list)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80264a-a7d7-4ef3-8597-6968b968239c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Outputs splits to file\n",
    "#full_set_coref_edges_obs.to_csv('CoRef_obs.csv', sep ='\\t', index=False, header=False, columns=['email', 'alt_email', 'exists'])\n",
    "#coref_truth.to_csv('CoRef_truth.csv', sep ='\\t', index=False, header=False, columns=['email', 'alt_email', 'exists'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d5640e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Process the Manager edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86749e40-88ec-4689-9f3e-819bbc6539b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2a88af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in the observed email-submgr.\n",
    "# need to rename one of the columns due to key collision\n",
    "# use copy for safety\n",
    "!cp $FILE_GROUND_TRUTH_MANAGES_EDGES .\n",
    "!sed -i 's/\\temail/\\tother_email/2g' enron.UNDIRECTED.email-submgr.tab\n",
    "\n",
    "manager_edges = load_table('enron.UNDIRECTED.email-submgr.tab')\n",
    "\n",
    "# FIXME: can probably omit this line\n",
    "manager_edges.drop('NOTEXIST,EXIST', axis=1, inplace=True)\n",
    "\n",
    "resolve_column_type(manager_edges)\n",
    "\n",
    "manager_edges.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843325f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6562e1-e3a6-4136-888d-cb2441f07dad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab necessary columns, in preparation for dumping the whole ground truth data\n",
    "manager_edges_data = manager_edges[['email','other_email', 'exists']].copy()\n",
    "\n",
    "# convert existence column to boolean, so PSL can ground faster\n",
    "manager_edges_data = manager_edges_data.replace({'exists': exists_map})\n",
    "\n",
    "# Since it's undirected, add in the reverse edges.\n",
    "manager_edges_data_sym = manager_edges_data[['other_email', 'email', 'exists']].copy()\n",
    "manager_edges_data_sym.rename(columns = {'other_email':'email', 'email':'other_email'}, inplace = True)\n",
    "\n",
    "manager_edges_data = pd.concat([manager_edges_data, manager_edges_data_sym])\n",
    "\n",
    "# Calculated the missing edges that were blocked.\n",
    "missing_edges = {pair for pair in itertools.permutations(email_nodes['id'], 2)} - {pair for pair in zip(manager_edges_data['email'], manager_edges_data['other_email'])}\n",
    "\n",
    "# add in the missing edges\n",
    "row_list = []\n",
    "for email, other_email in missing_edges:\n",
    "    row_dict = {'email':email, 'other_email':other_email, 'exists':0 }\n",
    "    row_list.append(row_dict)\n",
    "\n",
    "full_set_manager_edges_data = pd.concat([manager_edges_data, pd.DataFrame(row_list)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a317ea38-d577-48b9-831c-3fee59f6599d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Outputs to file\n",
    "# full_set_manager_edges_data.to_csv('Manages_data.csv', sep ='\\t', index=False, header=False, columns=['email', 'other_email', 'exists'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e5d542-835f-42f8-9ff4-0f9d5cb3a684",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate splits for PSL predicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e82ddb-5ef1-4bc8-96bd-a0fc04b8ef72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab the sample from the original experiment, this will allow us to calculate observations and targets.\n",
    "sample_manager_edges = load_table(FILE_SAMPLE_MANAGES_EDGES)\n",
    "resolve_column_type(sample_manager_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e8ebc-9975-4531-bdef-8cbcf3b7b9be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into observed and targets (AKA train and test)\n",
    "manager_edges_obs = manager_edges[manager_edges['id'].isin(sample_manager_edges[sample_manager_edges['exists'].notna()]['id'])]\n",
    "manager_edges_truth = manager_edges[manager_edges['id'].isin(sample_manager_edges[sample_manager_edges['exists'].isna()]['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff2da2-19e6-45b3-b252-c21e43634149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(manager_edges_obs))\n",
    "print(len(manager_edges_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b64120c-1136-45e9-8195-af01d11be92b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab the necessary columns\n",
    "manages_obs = manager_edges_obs[['email', 'other_email', 'exists']].copy()\n",
    "manages_truth = manager_edges_truth[['email', 'other_email', 'exists']].copy()\n",
    "\n",
    "# convert existence column to boolean, so PSL can ground faster\n",
    "manages_obs = manages_obs.replace({'exists': exists_map})\n",
    "manages_truth = manages_truth.replace({'exists': exists_map})\n",
    "\n",
    "# Since it's undirected, add in the reverse edges.\n",
    "manages_obs_sym = manages_obs[['other_email', 'email', 'exists']].copy()\n",
    "manages_truth_sym = manages_truth[['other_email', 'email', 'exists']].copy()\n",
    "\n",
    "manages_obs_sym.rename(columns = {'other_email':'email', 'email':'other_email'}, inplace = True)\n",
    "manages_truth_sym.rename(columns = {'other_email':'email', 'email':'other_email'}, inplace = True)\n",
    "\n",
    "manages_obs = pd.concat([manages_obs, manages_obs_sym])\n",
    "manages_truth = pd.concat([manages_truth, manages_truth_sym])\n",
    "\n",
    "# Calculated the missing edges that were blocked. Note the last set prevents cross contamination\n",
    "missing_edges = {pair for pair in itertools.permutations(email_nodes['id'], 2)} - {pair for pair in zip(manages_obs['email'], manages_obs['other_email'])} - {pair for pair in zip(manages_truth['email'], manages_truth['other_email'])}\n",
    "\n",
    "# add in the missing edges\n",
    "row_list = []\n",
    "for email, other_email in missing_edges:\n",
    "    row_dict = {'email':email, 'other_email':other_email, 'exists':0 }\n",
    "    row_list.append(row_dict)\n",
    "\n",
    "full_set_manages_obs = pd.concat([manages_obs, pd.DataFrame(row_list)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644930fb-35b8-4332-8de9-522cc549b184",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#full_set_manages_obs.to_csv('Manages_obs.csv', sep ='\\t', index=False, header=False, columns=['email', 'other_email', 'exists'])\n",
    "#manages_truth.to_csv('Manages_truth.csv', sep ='\\t', index=False, header=False, columns=['email', 'other_email', 'exists'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cfb500-d84b-438a-90be-2b756b8f3ac0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train a local classifier/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19deb381-edd3-4fb1-a637-52f5e80c37f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97162ad9-f8b0-4130-92a7-839736c0a8b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Node Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3af3d1-d9d5-4286-90b2-885c0c3e694f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "email_nodes_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ee8c31-5a59-47e3-ade1-a0171371504e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x = email_nodes_obs.drop(['id', 'emailaddress', 'title', 'numsent', 'numreceived', 'numexchanged'], axis = 1).fillna(0)\n",
    "train_y = email_nodes_obs['title']\n",
    "\n",
    "test_x = email_nodes_truth.drop(['id', 'emailaddress', 'title', 'numsent', 'numreceived', 'numexchanged'], axis = 1).fillna(0)\n",
    "test_y = email_nodes_truth['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb29f6f-a33d-4f86-beaf-4e13092a473f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# classifier = svm.LinearSVC()\n",
    "classifier = LogisticRegression(max_iter=300)\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfafc5b6-275d-4a61-a7ad-086fa3c268ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = classifier.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cde8e9-95ae-43d9-8c4d-b1db8dafd0ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f6f75-da1b-491a-8f7f-feb5566eec28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5c3d9-8db3-4118-a70a-444f8086b659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# title_map = {\"other\": 0, \"manager\": 1, \"specialist\": 2, \"director\": 3, \"executive\": 4}\n",
    "\n",
    "classifier.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629f47db-c363-4b39-abba-ee95f2718588",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use probabilities for PSL observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2e4ec-389c-4165-9ae3-2c38a6b783b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_EmailHasTitle_probabilities = classifier.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d908e94d-9dc2-44a2-994f-8c69d67457cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_EmailHasTitle_obs = pd.DataFrame()\n",
    "row_list = []\n",
    "# build a table\n",
    "for index, probabilities in enumerate(local_EmailHasTitle_probabilities):\n",
    "    for class_index, probability in enumerate(probabilities):\n",
    "        row_dict = {'id': email_nodes_truth.iloc[index]['id'], 'title': title_map[classifier.classes_[class_index]], 'exists': probability}\n",
    "        row_list.append(row_dict)\n",
    "        #print(email_nodes_truth.iloc[index]['id'], \"\\t\", title_map[classifier.classes_[class_index]], \"\\t\", probability)\n",
    "\n",
    "local_EmailHasTitle_obs = pd.concat([local_EmailHasTitle_obs, pd.DataFrame(row_list)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd751dd-373e-4cc1-a6fd-a94b920c1928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#local_EmailHasTitle_obs.to_csv('Local_EmailHasLabel_obs.csv', sep ='\\t', index=False, header=False, columns=['id', 'title', 'exists'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce84efb-d998-4a59-ae6b-66173af05b74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b39144-e3bf-4ea8-92ca-44bba23765ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager_edges_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b16e26e-20d3-4fd7-82ef-3ad16e0f310c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x = manager_edges_obs.drop(['id', 'numexchanged', 'email', 'other_email', 'exists'], axis = 1).fillna(0)\n",
    "train_y = manager_edges_obs['exists']\n",
    "\n",
    "test_x = manager_edges_truth.drop(['id', 'numexchanged', 'email', 'other_email', 'exists'], axis = 1).fillna(0)\n",
    "test_y = manager_edges_truth['exists']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3d569a-0462-46ee-b3d7-9fa855be4a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f49109-1029-43d9-9c55-3d14265d4d58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(max_iter=300)\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747ccb9-4f5e-4a66-88a3-c9746190e941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = classifier.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be4925b-f34f-45d0-aed2-66f43dc737a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96d14ce-56ce-42ec-83c3-ca334059bd0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use probabilities for PSL observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce15c4-4de3-4215-ad05-f25270f4b7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_Manages_probabilities = classifier.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1538253a-284e-4f26-9611-2497a2db5f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_Manages_obs = pd.DataFrame()\n",
    "row_list = []\n",
    "# build a table\n",
    "for index, probabilities in enumerate(local_Manages_probabilities):\n",
    "    row_dict = {'email': manager_edges_truth.iloc[index]['email'], 'other_email': manager_edges_truth.iloc[index]['other_email'], 'exists': exists_map[classifier.classes_[np.argmax(probabilities)]]}\n",
    "    row_list.append(row_dict)\n",
    "    #print(email_nodes_truth.iloc[index]['id'], \"\\t\", title_map[classifier.classes_[class_index]], \"\\t\", probability)\n",
    "\n",
    "local_Manages_obs = pd.concat([local_Manages_obs, pd.DataFrame(row_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf55a131-02cd-4b7f-ab8c-4f90ba83d178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_Manages_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f6dc2-33e8-472f-b54a-5ff2de0533c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since it's undirected, add in the reverse edges.\n",
    "local_Manages_obs_sym = local_Manages_obs[['other_email', 'email', 'exists']].copy()\n",
    "\n",
    "local_Manages_obs_sym.rename(columns = {'other_email':'email', 'email':'other_email'}, inplace = True)\n",
    "\n",
    "local_Manages_obs = pd.concat([local_Manages_obs, local_Manages_obs_sym])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bb9bfd-2aa7-4b47-8862-26d02d62eee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#local_Manages_obs.to_csv('Local_Manages_obs.csv', sep ='\\t', index=False, header=False, columns=['email', 'other_email', 'exists'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aea56bc-8610-496b-86ab-93eb497bc83a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Entity Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec3ca29-b8ac-4896-9f09-756a0b7f272e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from strsimpy.qgram import QGram\n",
    "from scipy.spatial import distance\n",
    "\n",
    "qgram = QGram(1)\n",
    "\n",
    "node_to_email = dict(zip(email_nodes['id'], email_nodes['emailaddress']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e14e7e-ce03-4d95-8999-441bb7ad3bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate features for Training set\n",
    "\n",
    "train_x = full_set_coref_edges_obs.copy()\n",
    "\n",
    "train_x['address_similarity'] = 0.0\n",
    "train_x['bow_cosine_similarity'] = 0.0\n",
    "train_x['bow_jaccard_similarity'] = 0.0\n",
    "\n",
    "\n",
    "for index in train_x.index:\n",
    "    string_similarity = qgram.distance(node_to_email[train_x.iloc[index]['email']], node_to_email[train_x.iloc[index]['alt_email']])\n",
    "    train_x.loc[index, 'address_similarity'] = string_similarity\n",
    "\n",
    "    bow_cosine_similarity = distance.cosine(np.nan_to_num(list(email_nodes[email_nodes['id'] == train_x.iloc[index]['email']].iloc[0][5:-1])), np.nan_to_num(list(email_nodes[email_nodes['id'] == train_x.iloc[index]['alt_email']].iloc[0][5:-1])))\n",
    "    train_x.loc[index, 'bow_cosine_similarity'] = bow_cosine_similarity\n",
    "\n",
    "    bow_jaccard_similarity = distance.jaccard(np.nan_to_num(list(email_nodes[email_nodes['id'] == train_x.iloc[index]['email']].iloc[0][5:-1])), np.nan_to_num(list(email_nodes[email_nodes['id'] == train_x.iloc[index]['alt_email']].iloc[0][5:-1])))\n",
    "    train_x.loc[index, 'bow_jaccard_similarity'] = bow_jaccard_similarity\n",
    "    \n",
    "\n",
    "train_x = train_x.drop(['email', 'alt_email', 'exists'], axis = 1)\n",
    "train_y = full_set_coref_edges_obs['exists'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c99623a-7cb1-4497-adec-fc111061e4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test set\n",
    "\n",
    "test_x = coref_truth.copy()\n",
    "test_y = coref_truth['exists'].copy()\n",
    "\n",
    "test_x['address_similarity'] = 0.0\n",
    "test_x['bow_cosine_similarity'] = 0.0\n",
    "test_x['bow_jaccard_similarity'] = 0.0\n",
    "\n",
    "for index in test_x.index:\n",
    "    string_similarity = qgram.distance(node_to_email[test_x.iloc[index]['email']], node_to_email[test_x.iloc[index]['alt_email']])\n",
    "    test_x.loc[index, 'address_similarity'] = string_similarity\n",
    "\n",
    "    bow_cosine_similarity = distance.cosine(np.nan_to_num(list(email_nodes[email_nodes['id'] == test_x.iloc[index]['email']].iloc[0][5:-1])), np.nan_to_num(list(email_nodes[email_nodes['id'] == test_x.iloc[index]['alt_email']].iloc[0][5:-1])))\n",
    "    test_x.loc[index, 'bow_cosine_similarity'] = bow_cosine_similarity\n",
    "\n",
    "    bow_jaccard_similarity = distance.jaccard(np.nan_to_num(list(email_nodes[email_nodes['id'] == test_x.iloc[index]['email']].iloc[0][5:-1])), np.nan_to_num(list(email_nodes[email_nodes['id'] == test_x.iloc[index]['alt_email']].iloc[0][5:-1])))\n",
    "    test_x.loc[index, 'bow_jaccard_similarity'] = bow_jaccard_similarity\n",
    "    \n",
    "test_x = test_x.drop(['email', 'alt_email', 'exists'], axis = 1)\n",
    "test_y = coref_truth['exists'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b86007-255e-4d60-897c-527b95d3ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48f3038-12f4-4bdf-8ecb-3e8259067151",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e929e41b-8b64-459b-aa83-82f91a6a8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ecbe2-643d-43c2-9c0f-5d4f726b6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(test_y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb28082-32c8-4b1a-a977-643449b7c338",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use probabilities for PSL observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427ecd7e-f638-4898-a37e-fe87bda74c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7eb557-7aad-4911-8951-84cbc4655ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_CoRef_probabilities = classifier.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168909c3-21e8-4976-b9e7-f04603746cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_CoRef_obs = pd.DataFrame()\n",
    "row_list = []\n",
    "# build a table\n",
    "for index, probabilities in enumerate(local_CoRef_probabilities):\n",
    "    row_dict = {'email': int(coref_truth.iloc[index]['email']), 'alt_email': int(coref_truth.iloc[index]['alt_email']), 'exists': probabilities[1]}\n",
    "    row_list.append(row_dict)\n",
    "    #print(email_nodes_truth.iloc[index]['id'], \"\\t\", title_map[classifier.classes_[class_index]], \"\\t\", probability)\n",
    "\n",
    "local_CoRef_obs = pd.concat([local_CoRef_obs, pd.DataFrame(row_list)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f1557-275a-43f1-9b91-c127b4466463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#local_CoRef_obs.to_csv('Local_CoRef_obs.csv', sep ='\\t', index=False, header=False, columns=['email', 'alt_email', 'exists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d019d-a8fa-4b6d-8f25-5821944d2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check the positive instances\n",
    "set_1 = {(pair[0], pair[1]) for pair in zip(local_CoRef_obs[local_CoRef_obs['exists'] > 0.5]['email'], local_CoRef_obs[local_CoRef_obs['exists'] > 0.5]['alt_email'])}\n",
    "set_2 = {(pair[0], pair[1]) for pair in zip(coref_truth[coref_truth['exists'] == 1]['email'], coref_truth[coref_truth['exists'] == 1]['alt_email'])}\n",
    "set_2 & set_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92b1315-ef85-439b-8e23-8c9dd8c90e33",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate Similarity Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07efe1fb-2264-42cf-8530-ff7a87464e14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Entity Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf731375-2130-4432-b214-db5f7b4b5834",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Email Address similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5d563-d694-4718-b2d9-124d0bb09be3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# qgram = QGram(1)\n",
    "# print(qgram.distance('ABCD', 'ABCE'))\n",
    "email_nodes[email_nodes['id'] == 268]['emailaddress'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60b0d45-4d86-4498-9b7f-b6cf243a8c05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "email_pairs = {pair for pair in itertools.combinations(email_nodes['id'], 2)}\n",
    "\n",
    "qgram = QGram(1)\n",
    "\n",
    "sim_email = pd.DataFrame()\n",
    "row_list = []\n",
    "\n",
    "i = 0\n",
    "for pair in email_pairs:\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    i += 1\n",
    "\n",
    "    email_1 = email_nodes[email_nodes['id'] == pair[0]]['emailaddress'].iloc[0]\n",
    "    email_2 = email_nodes[email_nodes['id'] == pair[1]]['emailaddress'].iloc[0]    \n",
    "\n",
    "    string_similarity = qgram.distance(email_1, email_2)\n",
    "\n",
    "    row_dict = {'email':pair[0], 'other_email':pair[1], 'qgram_sim':string_similarity}\n",
    "    row_list.append(row_dict)\n",
    "    \n",
    "sim_email = pd.concat([sim_email, pd.DataFrame(row_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f161ec0b-5bcc-4499-bce3-ae7c6e49a73b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sim_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b536de52-4cf5-40a3-b4d5-dec90e68d1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since it's undirected, add in the reverse edges.\n",
    "sim_email_sym = sim_email[['other_email', 'email', 'qgram_sim']].copy()\n",
    "\n",
    "sim_email_sym.rename(columns = {'other_email':'email', 'email':'other_email'}, inplace = True)\n",
    "\n",
    "total_sim_email = pd.concat([sim_email, sim_email_sym], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdf9ba4-0b2e-4f67-ab30-42592f44f80e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_sim_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858978df-7abc-4675-8f19-a00486d8e795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_similar = []\n",
    "for sim in total_sim_email['qgram_sim']:\n",
    "    is_similar.append(float(sim < 3))\n",
    "    \n",
    "total_sim_email[\"is_similar\"] = is_similar\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0406d48-f012-4435-a243-d48e64d54bb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_sim_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47011ebe-09dd-42bc-b379-460fe2c8e70f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_sim_email.to_csv('Sim_Email_thresh_3.csv', sep ='\\t', index=False, header=False, columns=['email', 'other_email', 'is_similar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424a298-1144-4ae7-bbdf-1b85f8e1b9a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sim_email.to_csv('Sim_Email.csv', sep ='\\t', index=False, header=False, columns=['email', 'other_email', 'qgram_sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db78f04-dd02-4a1e-8abe-c7453927c74a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sanity Check, this should print mostly \"exists=1.0\"\n",
    "\n",
    "for pair in zip(sim_email[sim_email['qgram_sim'] < 5]['email'], sim_email[sim_email['qgram_sim'] < 5]['other_email']):\n",
    "    print(full_set_coref_edges_data[(full_set_coref_edges_data['email'] == pair[0]) & (full_set_coref_edges_data['alt_email'] == pair[1])]['exists'])\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4d997b-671d-4c7a-b13a-bf059d1aa463",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bag of words similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db77662-be4c-46db-8732-db764d178e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These similarity features will be used for PSL predicates instead of a local classifier.\n",
    "from scipy.spatial import distance\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609941be-118d-4376-a99b-17de2022bae0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sim_bow = pd.DataFrame()\n",
    "row_list = []\n",
    "\n",
    "\n",
    "for pair in email_pairs:\n",
    "    entity_1 = email_nodes[email_nodes['id'] == pair[0]]\n",
    "    entity_2 = email_nodes[email_nodes['id'] == pair[1]]\n",
    "    \n",
    "    bow_1 = entity_1.iloc[0][5:-1]\n",
    "    bow_2 = entity_2.iloc[0][5:-1]\n",
    "    # FIXME: Jaccard distance needs to be on sets\n",
    "    row_dict = {'email':pair[0], 'other_email':pair[1], 'jaccard_sim_bow':distance.jaccard(list(bow_1), list(bow_2)), 'cosine_sim_bow':distance.cosine(np.nan_to_num(list(bow_1)), np.nan_to_num(list(bow_2)))}\n",
    "    row_list.append(row_dict)\n",
    "    \n",
    "sim_bow = pd.concat([sim_bow, pd.DataFrame(row_list)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b817ac4-8d5b-4f34-b3be-6d2b58198d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_bow['jaccard_sim_bow'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d1e36-fa2b-4c94-85d8-8d6f328f072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_bow['cosine_sim_bow'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05548168-0a53-4e39-9863-daae33a0f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since it's undirected, add in the reverse edges.\n",
    "sim_bow_sym = sim_bow[['other_email', 'email', 'jaccard_sim_bow', 'cosine_sim_bow']].copy()\n",
    "sim_bow_sym.rename(columns = {'other_email':'email', 'email':'other_email'}, inplace = True)\n",
    "\n",
    "sim_bow = pd.concat([sim_bow, sim_bow_sym])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ce440-ca4f-4327-b30b-d83324e73972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_bow.to_csv('Sim_Jaccard_Bow.csv', sep ='\\t', index=False, header=False, columns=['email', 'other_email', 'jaccard_sim_bow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff38e721-dcb7-4165-9239-b6a1fd184ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sim_bow.to_csv('Sim_Cosine_Bow.csv', sep ='\\t', index=False, header=False, columns=['email', 'other_email', 'cosine_sim_bow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8bf1c4-ab6d-4a3d-a05c-9a56bfb0e970",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Network Based silmilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2d4f9e-2d24-4e61-8106-ad83511be175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in the observed communication network\n",
    "# need to rename one of the columns due to key collision\n",
    "# use copy for safety\n",
    "!cp $FILE_GROUND_TRUTH_COMMUNICATION_EDGES .\n",
    "!sed -i 's/\\temail/\\tother_email/2g' enron.DIRECTED.sentto.tab\n",
    "\n",
    "communication_edges = load_table('enron.DIRECTED.sentto.tab')\n",
    "\n",
    "# FIXME: can probably omit this line\n",
    "# manager_edges.drop('NOTEXIST,EXIST', axis=1, inplace=True)\n",
    "\n",
    "resolve_column_type(communication_edges)\n",
    "\n",
    "communication_edges.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d436ee9-137f-4d7f-ac82-eb691cbeedc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "communication_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a8c3f7-2b7c-4804-b2c1-6cee4b1f18cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in existence\n",
    "communication_edges['exists'] = 1.0\n",
    "\n",
    "# Calculated the missing edges that were blocked.\n",
    "missing_edges = {pair for pair in itertools.permutations(email_nodes['id'], 2)} - {pair for pair in zip(communication_edges['email'], communication_edges['other_email'])}\n",
    "# add in the missing edges\n",
    "row_list = []\n",
    "for email, alt_email in missing_edges:\n",
    "    row_dict = {'email':email, 'other_email':alt_email, 'exists':0 }\n",
    "    row_list.append(row_dict)\n",
    "\n",
    "full_set_communication_edges = pd.concat([communication_edges, pd.DataFrame(row_list)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c433c602-9160-4e3f-9f6e-373eebad0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_set_communication_edges.to_csv('Communicates.csv', sep ='\\t', index=False, header=False, columns=['email', 'other_email', 'exists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf29363-9ef7-4aa8-b0d8-0f3a847a7e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare ground truth\n",
    "coref_map = {(int(full_set_coref_edges_data.iloc[index]['email']), int(full_set_coref_edges_data.iloc[index]['alt_email'])):full_set_coref_edges_data.iloc[index]['exists'] for index in full_set_coref_edges_data.index}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c89823-a693-4858-9208-64f860d89e36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sim_network = pd.DataFrame()\n",
    "row_list = []\n",
    "\n",
    "\n",
    "for id_1, id_2 in email_pairs:\n",
    "    \n",
    "    adjacent_nodes_1 = set(communication_edges[communication_edges['email'] == id_1]['other_email'])\n",
    "    adjacent_nodes_2 = set(communication_edges[communication_edges['email'] == id_2]['other_email'])\n",
    "\n",
    "    entity_1 = email_nodes[email_nodes['id'] == id_1]\n",
    "    entity_2 = email_nodes[email_nodes['id'] == id_2]\n",
    "    \n",
    "    bow_1 = entity_1.iloc[0][5:-1]\n",
    "    bow_2 = entity_2.iloc[0][5:-1]\n",
    "\n",
    "\n",
    "    jaccard_sim =  len(adjacent_nodes_1 & adjacent_nodes_2) / len(adjacent_nodes_1 | adjacent_nodes_2 ) if len(adjacent_nodes_1 | adjacent_nodes_2) != 0 else 0\n",
    "    dice_sim =  (2 * len(adjacent_nodes_1 & adjacent_nodes_2) ) / (len(adjacent_nodes_1) + len(adjacent_nodes_2)) if len(adjacent_nodes_1) + len(adjacent_nodes_2) != 0 else 0\n",
    "    \n",
    "    # dice_sim = \n",
    "    \n",
    "    row_dict = {'email':id_1, 'other_email':id_2, 'jaccard_sim_network':jaccard_sim, 'dice_sim_network':dice_sim, 'jaccard_sim_bow':distance.jaccard(list(bow_1), list(bow_2)), 'cosine_sim_bow':distance.cosine(np.nan_to_num(list(bow_1)), np.nan_to_num(list(bow_2))), 'is_coref': coref_map[(id_1, id_2)]}\n",
    "    row_list.append(row_dict)\n",
    "    \n",
    "sim_network = pd.concat([sim_network, pd.DataFrame(row_list)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceef394c-2b2c-4337-ab6d-9d13b4ad0739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since it's undirected, add in the reverse edges.\n",
    "sim_network_sym = sim_network[['other_email', 'email', 'jaccard_sim_network', 'dice_sim_network', 'jaccard_sim_bow', 'cosine_sim_bow', 'is_coref']].copy()\n",
    "sim_network_sym.rename(columns = {'other_email':'email', 'email':'other_email'}, inplace = True)\n",
    "\n",
    "sim_network = pd.concat([sim_network, sim_network_sym], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5eeb53-c2e1-465d-80ae-54651bea2a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acee4f8-cfb0-4e33-89ec-88c86dc8cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim_network.to_csv('Sim_network.csv', sep ='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d438f6-e20e-40e3-baaf-3f371e354834",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbab0be-2762-4509-b379-dd7c917bcfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Computes RMSEs from ground truth and similarity metric\n",
    "# Returns (Total RMSE, Positive RMSE, Negative RMSE )\n",
    "def compute_rmse(table, similarity):\n",
    "    total_rmse = math.sqrt(mean_squared_error(table['is_coref'], table[similarity]))\n",
    "    pos_rmse = math.sqrt(mean_squared_error(table[table['is_coref'] == 1]['is_coref'], table[table['is_coref'] == 1][similarity]))\n",
    "    neg_rmse = math.sqrt(mean_squared_error(table[table['is_coref'] == 0]['is_coref'], table[table['is_coref'] == 0][similarity]))\n",
    "    print(\"total_rmse:\\tpos_rmse:\\tneg_rmse: \")\n",
    "    print(total_rmse, pos_rmse, neg_rmse, sep=\"\\t\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e56ebf-fd6d-493f-9130-ec18d0a9b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_rmse(sim_network, 'dice_sim_network')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82649c24-9eff-4e56-9a56-faf252ca0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_rmse(sim_network, 'jaccard_sim_network')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe03562-fe4b-43d0-a158-a53b28233c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(sim_network[\"jaccard_sim_network\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e376ca68-b100-45b4-b93c-4af281e08a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sim_network[sim_network[\"is_coref\"] == 1][\"jaccard_sim_network\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90f1a8b-0e56-42b5-81d9-5fb4fd3f8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sim_network[sim_network[\"is_coref\"] == 0][\"jaccard_sim_network\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc95bd-120b-497a-98b9-98d37c760cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_network.to_csv('Sim_Jaccard_Network.csv', sep ='\\t', index=False, header=False, columns=['email', 'other_email', 'jaccard_sim_network'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
